{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kaggle_plasticc (notebook 2)\n",
    "\n",
    "This notebook continues from Notebook 1.\n",
    "\n",
    "Here we attempt to reproduce some of the steps from leaders in the competition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------ the plan -----------\n",
    "0. review contributions by leaderboards\n",
    "1. create features.  Maybe try \"flux ratios\"\n",
    "2. LGB - create one of these\n",
    "3. do a simple logistic regression\n",
    "4. Stacking (ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# \"14th place solution\" (Belinda Trotta)\n",
    "* https://www.kaggle.com/c/PLAsTiCC-2018/discussion/75054#latest-448552\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull from github.\n",
    "* First observation...  its not a jupyter notebook!  It's .py files.\n",
    "* Is this going to be a recurring theme?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Files:\n",
    "  * There are exactly **four** python files in the git, plus the pdf\n",
    "  * calculate_features, predict, scale, split_test\n",
    "* Steps:\n",
    "  * download from github\n",
    "  * create \"data\" folder and save the challenge data there\n",
    "  * run split_test.py -> (splits into 100 hdf5 files) into \"data/split_100\" (15 minutes)\n",
    "  * run calculate_features.py -> generates 3 files in folder \"features) (3.5 hours)\n",
    "  * run predict.py -> train the model and make predictions (1.5 hours)\n",
    "  * run scale.py -> applies regularization to class 99 and generate submission file (couple minutes)\n",
    "  \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Solution #5 tidbits (revised with code)\" (CPMP)\n",
    "https://www.kaggle.com/c/PLAsTiCC-2018/discussion/75050#latest-447982"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull from github\n",
    "* First observation - super well documented (crisp) README.\n",
    "* nice folder structure\n",
    "  * ***-> take a minute to review this***\n",
    "* this one is a jupyter notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4th Place Solution with Github Repo (Ahmet Erdem)\n",
    "https://www.kaggle.com/c/PLAsTiCC-2018/discussion/75011#latest-444878"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull from github\n",
    "\n",
    "* *** -> review the files and structure\n",
    "* --> This is python\n",
    "* --> has a requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st place solution (Kyle Boone)Â¶\n",
    "https://www.kaggle.com/c/PLAsTiCC-2018/discussion/75033#latest-457546\n",
    "* an astrophysicist\n",
    "* code available on https://github.com/kboone/avocado\n",
    "* Summary   \n",
    "  * most of work was put into separating super-novae apart because (\"everything else was fairly easy to tell apart\")\n",
    "  * ***-> in other words - use time wisely - ML will solve part of the prediction easily - focus where ML needs help***\n",
    "  * augmented training set by \"degrading the well-observed lightcurves in the training set to match the properties of the test set\".\n",
    "  * ***-> in other words - the training set only had a few examples of well obseved light curves so it is necessary to augment these to prevent over-fit***\n",
    "  * use gaussian process to predict light curves\n",
    "  * ***-> what does this mean? - review code***\n",
    "  * measured 200 features on raw data and Gaussian process predictions\n",
    "  * trained single LGBM model with 5-fold cross-validation\n",
    "* ***-> There is a WEBSITE on \"Avocado\" https://avocado-classifier.readthedocs.io/en/latest/***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on Avocado / Kyle Boon\n",
    "* steps to install and run are at\n",
    "  * https://avocado-classifier.readthedocs.io/en/latest/plasticc.html\n",
    "* NOTE: author ran using ***CentOS (not Windows)***\n",
    "* Installing **\"avocado\"**\n",
    "  * https://avocado-classifier.readthedocs.io/en/latest/index.html#installation\n",
    "  * recommends ***anacoda*** (not virtualenv) with packages from ***conda-forge channel***\n",
    "  * uses python \"setuptools\" to:\n",
    "    * install avocado module, AND\n",
    "    * install \"scripts that can be used to process datasets on the command line for a variety of tasks\"\n",
    "    * ***does anyone understand the idea behind setuptools?  designed a project using it?***\n",
    "    * ***above is a THE way to distribute a package and scripts***\n",
    "  * this fails on my windows/virtualenv... building \"george\"\n",
    "    \n",
    "    \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \"george\" by the way is itself very interesting\n",
    "  * https://george.readthedocs.io/en/latest/tutorials/bayesopt/\n",
    "  * https://george.readthedocs.io/en/latest/tutorials/first/\n",
    "  * https://george.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* the files include:\n",
    "  * /scripts (python)\n",
    "    * augment, convert, download, featurize, predict, train,\n",
    "  * /avocado\n",
    "    * astronomical_object, augment, classifier, dataset, features, instruments, plasticc, settings, utils\n",
    "  * /docs\n",
    "    * this is ***sphinx doc builder***.  Makefile, plasticc.rst, refernces.rst\n",
    "  * /notebooks\n",
    "    * avocado_paper_figures.ipynb  <- would be nice to see this but cannot until \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I'm going to leave this as a future exercise - all VERY interesting but I don't want to debug George and/or stand up a CentOS VM.  There is lower hanging fruit.\n",
    "### The approach and algorithms/techniques are outstanding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
