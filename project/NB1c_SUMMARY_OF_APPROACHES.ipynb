{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Summary\n",
    "Here are approaches taken by top leaderboard entrants on the Kaggle PLAsTiCC-2018 competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | Rank | Who | Code? | Feature Engineering / Augmentation | Modeling | url |\n",
    "| --- | ----------- |:----------- |:----------- |:----------- |:----------- | :--- |\n",
    "| - | 20th | GIBA | no | 250 features<br> ***feets(feature extractor for timeseries)***<br>aggregations, statistics by hand | LGBs, SVCs -> \"stack ensemble\" | https://www.kaggle.com/c/PLAsTiCC-2018/discussion/75262#latest-527064 |\n",
    "|   | 9th | Garreta | no | 8000 pruned to 180 <br>***catboost(library for categorical data)*** <br> @manugangler's kernel (light curves to microlensing event) | lgb + catboost + nn -> stacking | https://www.kaggle.com/c/PLAsTiCC-2018/discussion/75316#latest-495584 |\n",
    "| | 2nd | Silogram | no | ? | (7) RNN -> ensemble (2 LGBs) | https://www.kaggle.com/c/PLAsTiCC-2018/discussion/75059#latest-462457 |\n",
    "| | 14th | BTrotta | YES +pdf | ~200(x4) features <br>elementary operations (no curve fitting)<br>***bayes*** for removing noise from flux | LGB | https://www.kaggle.com/c/PLAsTiCC-2018/discussion/75054#latest-448552 |\n",
    "| | 5th | CPMP | YES (well documented) | hand crafted from light curves (used Pandas) <br>did NOT use packages (light gatspy, cesium, tsfresh) \"slower\" and \"not as good\" <br>***objective function(?)*** | lightGBM (almost exclusively) | https://www.kaggle.com/c/PLAsTiCC-2018/discussion/75050#latest-447982 |\n",
    "| | 13th | Blonde | no | Parametric curve fittings (***Bazin paper***) <br> ***cesium*** (ratios, std, skew) <br> ***feets*** <br>augmentation on flux | 50/50 blend of two LGBM models | https://www.kaggle.com/c/PLAsTiCC-2018/discussion/75134#latest-445370 |\n",
    "| | 4th | Ahmet Erdem | YES | Ratios (passband / all passbands) <br>***log-transformed*** (gives mult,div to NN)  <br> ***Sub-models*** to create features | LGB + NN + Stacking | https://www.kaggle.com/c/PLAsTiCC-2018/discussion/75011#latest-444878 |\n",
    "| | 12th | Daniel Bi | no | non-frequency (light curves): hand-gen inspired by FATS = 50-60 features <br> frequency: ***Lomb-Scargle*** (detect periodicity in unevenly spaced observations) with curve fitting based on \"Bazin\" paper  | Three LGM + ensemble | https://www.kaggle.com/c/PLAsTiCC-2018/discussion/75237#latest-446568 |\n",
    "| | 1st | Kyle Boone | YES | STRATEGY = focus on what ML needs -> most effort in separating super-novae because everything else was fairly easy to tell apart <br> 200 features <br> **George** (Gaussian Process Regression) <br> augment training set by \"degrading...to match test set\" | single LGBM model with 5-fold cross-validation | https://www.kaggle.com/c/PLAsTiCC-2018/discussion/75033#latest-457546 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
