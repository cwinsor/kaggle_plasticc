{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook we continue to investigate \"btrotta\".   \n",
    "Here we are walking the code (reverse engineering \"calculate_features.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I want to summarize this first (from her .pdf)\n",
    "* uses LightGBM (linear gradient boosting classification tree)\n",
    "* uses elementary operations to calculate features (no curve fitting - keeps runtime down)\n",
    "  * Bayesian approach to removing noise\n",
    "  * adding features based on scaled flux values\n",
    "  * adding features to capture behavior around the peak\n",
    "  * understanding how to optimize the metrix\n",
    "  \n",
    "  training \n",
    "prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-12 10:48:11.628547\n",
      "reading data\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())\n",
    "print(\"reading data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "col_dict = {'mjd': np.float64, 'flux': np.float32, 'flux_err': np.float32, 'object_id': np.int32, 'passband': np.int8,\n",
    "            'detected': np.int8}\n",
    "train_meta = pd.read_csv(os.path.join('data', 'training_set_metadata.csv'))\n",
    "train = pd.read_csv(os.path.join('data', 'training_set.csv'), dtype=col_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_meta = pd.read_csv(os.path.join('data', 'test_set_metadata.csv'))\n",
    "test = pd.read_csv(os.path.join('data', 'test_set_sample.csv'), dtype=col_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_meta = pd.concat([train_meta, test_meta], axis=0, ignore_index=True, sort=True).reset_index()\n",
    "all_meta.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7848, 12)\n",
      "(1421705, 6)\n",
      "(3492890, 11)\n",
      "(1000000, 6)\n",
      "(3500738, 12)\n"
     ]
    }
   ],
   "source": [
    "print(train_meta.shape)\n",
    "print(train.shape)\n",
    "print(test_meta.shape)\n",
    "print(test.shape)\n",
    "print(all_meta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* hmmm the \"training\" dataset has 180 samples / object\n",
    "* the \"test\" dataset has 0.3 samples / object\n",
    "* I'm wondering how many objects are actually in the \"test\" dataset (does meta-data list objects not in test?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>ra</th>\n",
       "      <th>decl</th>\n",
       "      <th>gal_l</th>\n",
       "      <th>gal_b</th>\n",
       "      <th>ddf</th>\n",
       "      <th>hostgal_specz</th>\n",
       "      <th>hostgal_photoz</th>\n",
       "      <th>hostgal_photoz_err</th>\n",
       "      <th>distmod</th>\n",
       "      <th>mwebv</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>615</td>\n",
       "      <td>349.046051</td>\n",
       "      <td>-61.943836</td>\n",
       "      <td>320.796530</td>\n",
       "      <td>-51.753706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>713</td>\n",
       "      <td>53.085938</td>\n",
       "      <td>-27.784405</td>\n",
       "      <td>223.525509</td>\n",
       "      <td>-54.460748</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8181</td>\n",
       "      <td>1.6267</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>45.4063</td>\n",
       "      <td>0.007</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>730</td>\n",
       "      <td>33.574219</td>\n",
       "      <td>-6.579593</td>\n",
       "      <td>170.455585</td>\n",
       "      <td>-61.548219</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>40.2561</td>\n",
       "      <td>0.021</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>745</td>\n",
       "      <td>0.189873</td>\n",
       "      <td>-45.586655</td>\n",
       "      <td>328.254458</td>\n",
       "      <td>-68.969298</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3037</td>\n",
       "      <td>0.2813</td>\n",
       "      <td>1.1523</td>\n",
       "      <td>40.7951</td>\n",
       "      <td>0.007</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1124</td>\n",
       "      <td>352.711273</td>\n",
       "      <td>-63.823658</td>\n",
       "      <td>316.922299</td>\n",
       "      <td>-51.059403</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1934</td>\n",
       "      <td>0.2415</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>40.4166</td>\n",
       "      <td>0.024</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   object_id          ra       decl       gal_l      gal_b  ddf  \\\n",
       "0        615  349.046051 -61.943836  320.796530 -51.753706    1   \n",
       "1        713   53.085938 -27.784405  223.525509 -54.460748    1   \n",
       "2        730   33.574219  -6.579593  170.455585 -61.548219    1   \n",
       "3        745    0.189873 -45.586655  328.254458 -68.969298    1   \n",
       "4       1124  352.711273 -63.823658  316.922299 -51.059403    1   \n",
       "\n",
       "   hostgal_specz  hostgal_photoz  hostgal_photoz_err  distmod  mwebv  target  \n",
       "0         0.0000          0.0000              0.0000      NaN  0.017      92  \n",
       "1         1.8181          1.6267              0.2552  45.4063  0.007      88  \n",
       "2         0.2320          0.2262              0.0157  40.2561  0.021      42  \n",
       "3         0.3037          0.2813              1.1523  40.7951  0.007      90  \n",
       "4         0.1934          0.2415              0.0176  40.4166  0.024      90  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7848,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_meta[\"object_id\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7848,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"object_id\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3492890,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_meta[\"object_id\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3036,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"object_id\"].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# so it is confirmed - the \"test\" timeseries dataset actually has 3036 objects\n",
    "* The test_meta has many object_ids not in the test timeseries data\n",
    "* The test dataset has 330 samples/object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering (Section 1 in the .pdf) \n",
    "* in the code this is implemented as \"calculate_features.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Normalise the flux, following the Bayesian approach here:\n",
    "    # https://www.statlect.com/fundamentals-of-statistics/normal-distribution-Bayesian-estimation\n",
    "    # Similar idea (but not the same) as the normalisation done in the Starter Kit\n",
    "    # https://www.kaggle.com/michaelapers/the-plasticc-astronomy-starter-kit?scriptVersionId=6040398\n",
    "    prior_mean = all_data.groupby(['object_id', 'passband'])['flux'].transform('mean')\n",
    "    prior_std = all_data.groupby(['object_id', 'passband'])['flux'].transform('std')\n",
    "    prior_std.loc[prior_std.isnull()] = all_data.loc[prior_std.isnull(), 'flux_err']\n",
    "    obs_std = all_data['flux_err']  # since the above kernel tells us that the flux error is the 68% confidence interval\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "    all_data['bayes_flux'] = (all_data['flux'] / obs_std**2 + prior_mean / prior_std**2) \\\n",
    "                             / (1 / obs_std**2 + 1 / prior_std**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "    all_data.loc[all_data['bayes_flux'].notnull(), 'flux'] \\\n",
    "        = all_data.loc[all_data['bayes_flux'].notnull(), 'bayes_flux']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Estimate the flux at source, using the fact that light is proportional\n",
    "    # to inverse square of distance from source.\n",
    "    # This is hinted at here: https://www.kaggle.com/c/PLAsTiCC-2018/discussion/70725#417195\n",
    "    redshift = all_meta.set_index('object_id')[['hostgal_specz', 'hostgal_photoz']]\n",
    "    \n",
    "    redshift['redshift'] = redshift['hostgal_specz']\n",
    "    redshift.loc[redshift['redshift'].isnull(), 'redshift'] \\\n",
    "        = redshift.loc[redshift['redshift'].isnull(), 'hostgal_photoz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "    all_data = pd.merge(all_data, redshift, 'left', 'object_id')\n",
    "    nonzero_redshift = all_data['redshift'] > 0\n",
    "    all_data.loc[nonzero_redshift, 'flux'] = all_data.loc[nonzero_redshift, 'flux'] \\\n",
    "                                             * all_data.loc[nonzero_redshift, 'redshift']**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>mjd</th>\n",
       "      <th>passband</th>\n",
       "      <th>flux</th>\n",
       "      <th>flux_err</th>\n",
       "      <th>detected</th>\n",
       "      <th>bayes_flux</th>\n",
       "      <th>hostgal_specz</th>\n",
       "      <th>hostgal_photoz</th>\n",
       "      <th>redshift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>615</td>\n",
       "      <td>59750.4229</td>\n",
       "      <td>2</td>\n",
       "      <td>-544.784302</td>\n",
       "      <td>3.622952</td>\n",
       "      <td>1</td>\n",
       "      <td>-544.784302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>615</td>\n",
       "      <td>59750.4306</td>\n",
       "      <td>1</td>\n",
       "      <td>-816.397644</td>\n",
       "      <td>5.553370</td>\n",
       "      <td>1</td>\n",
       "      <td>-816.397644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>615</td>\n",
       "      <td>59750.4383</td>\n",
       "      <td>3</td>\n",
       "      <td>-471.340546</td>\n",
       "      <td>3.801213</td>\n",
       "      <td>1</td>\n",
       "      <td>-471.340546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>615</td>\n",
       "      <td>59750.4450</td>\n",
       "      <td>4</td>\n",
       "      <td>-388.477905</td>\n",
       "      <td>11.395031</td>\n",
       "      <td>1</td>\n",
       "      <td>-388.477905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>615</td>\n",
       "      <td>59752.4070</td>\n",
       "      <td>2</td>\n",
       "      <td>-681.815735</td>\n",
       "      <td>4.041204</td>\n",
       "      <td>1</td>\n",
       "      <td>-681.815735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1421700</td>\n",
       "      <td>130779836</td>\n",
       "      <td>60555.9838</td>\n",
       "      <td>4</td>\n",
       "      <td>-39.819046</td>\n",
       "      <td>46.477093</td>\n",
       "      <td>0</td>\n",
       "      <td>-39.819046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1421701</td>\n",
       "      <td>130779836</td>\n",
       "      <td>60560.0459</td>\n",
       "      <td>1</td>\n",
       "      <td>15.072200</td>\n",
       "      <td>18.947685</td>\n",
       "      <td>0</td>\n",
       "      <td>15.072200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1421702</td>\n",
       "      <td>130779836</td>\n",
       "      <td>60571.0225</td>\n",
       "      <td>5</td>\n",
       "      <td>30.733459</td>\n",
       "      <td>50.695290</td>\n",
       "      <td>0</td>\n",
       "      <td>30.733459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1421703</td>\n",
       "      <td>130779836</td>\n",
       "      <td>60585.9974</td>\n",
       "      <td>4</td>\n",
       "      <td>-23.413193</td>\n",
       "      <td>44.819859</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.413193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1421704</td>\n",
       "      <td>130779836</td>\n",
       "      <td>60588.0372</td>\n",
       "      <td>0</td>\n",
       "      <td>-40.707783</td>\n",
       "      <td>51.665123</td>\n",
       "      <td>0</td>\n",
       "      <td>-40.707783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1421705 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         object_id         mjd  passband        flux   flux_err  detected  \\\n",
       "0              615  59750.4229         2 -544.784302   3.622952         1   \n",
       "1              615  59750.4306         1 -816.397644   5.553370         1   \n",
       "2              615  59750.4383         3 -471.340546   3.801213         1   \n",
       "3              615  59750.4450         4 -388.477905  11.395031         1   \n",
       "4              615  59752.4070         2 -681.815735   4.041204         1   \n",
       "...            ...         ...       ...         ...        ...       ...   \n",
       "1421700  130779836  60555.9838         4  -39.819046  46.477093         0   \n",
       "1421701  130779836  60560.0459         1   15.072200  18.947685         0   \n",
       "1421702  130779836  60571.0225         5   30.733459  50.695290         0   \n",
       "1421703  130779836  60585.9974         4  -23.413193  44.819859         0   \n",
       "1421704  130779836  60588.0372         0  -40.707783  51.665123         0   \n",
       "\n",
       "         bayes_flux  hostgal_specz  hostgal_photoz  redshift  \n",
       "0       -544.784302            0.0             0.0       0.0  \n",
       "1       -816.397644            0.0             0.0       0.0  \n",
       "2       -471.340546            0.0             0.0       0.0  \n",
       "3       -388.477905            0.0             0.0       0.0  \n",
       "4       -681.815735            0.0             0.0       0.0  \n",
       "...             ...            ...             ...       ...  \n",
       "1421700  -39.819046            0.0             0.0       0.0  \n",
       "1421701   15.072200            0.0             0.0       0.0  \n",
       "1421702   30.733459            0.0             0.0       0.0  \n",
       "1421703  -23.413193            0.0             0.0       0.0  \n",
       "1421704  -40.707783            0.0             0.0       0.0  \n",
       "\n",
       "[1421705 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # aggregate features\n",
    "    band_aggs = all_data.groupby(['object_id', 'passband'])['flux'].agg(['mean', 'std', 'max', 'min']).unstack(-1)\n",
    "    band_aggs.columns = [x + '_' + str(y) for x in band_aggs.columns.levels[0]\n",
    "                          for y in band_aggs.columns.levels[1]]\n",
    "    all_data.sort_values(['object_id', 'passband', 'flux'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_0</th>\n",
       "      <th>mean_1</th>\n",
       "      <th>mean_2</th>\n",
       "      <th>mean_3</th>\n",
       "      <th>mean_4</th>\n",
       "      <th>mean_5</th>\n",
       "      <th>std_0</th>\n",
       "      <th>std_1</th>\n",
       "      <th>std_2</th>\n",
       "      <th>std_3</th>\n",
       "      <th>...</th>\n",
       "      <th>max_2</th>\n",
       "      <th>max_3</th>\n",
       "      <th>max_4</th>\n",
       "      <th>max_5</th>\n",
       "      <th>min_0</th>\n",
       "      <th>min_1</th>\n",
       "      <th>min_2</th>\n",
       "      <th>min_3</th>\n",
       "      <th>min_4</th>\n",
       "      <th>min_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>615</td>\n",
       "      <td>-3.280875</td>\n",
       "      <td>-385.686066</td>\n",
       "      <td>-134.144547</td>\n",
       "      <td>-121.101494</td>\n",
       "      <td>-55.947735</td>\n",
       "      <td>-47.465115</td>\n",
       "      <td>83.769569</td>\n",
       "      <td>601.738953</td>\n",
       "      <td>455.090881</td>\n",
       "      <td>335.389160</td>\n",
       "      <td>...</td>\n",
       "      <td>611.929565</td>\n",
       "      <td>445.658356</td>\n",
       "      <td>381.876129</td>\n",
       "      <td>377.994080</td>\n",
       "      <td>-116.758644</td>\n",
       "      <td>-1100.351196</td>\n",
       "      <td>-681.815735</td>\n",
       "      <td>-530.595459</td>\n",
       "      <td>-422.112610</td>\n",
       "      <td>-422.530182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>713</td>\n",
       "      <td>-9.234099</td>\n",
       "      <td>-3.436403</td>\n",
       "      <td>-2.644122</td>\n",
       "      <td>-3.357972</td>\n",
       "      <td>-3.113960</td>\n",
       "      <td>-6.039946</td>\n",
       "      <td>21.060951</td>\n",
       "      <td>17.820436</td>\n",
       "      <td>18.172571</td>\n",
       "      <td>20.005138</td>\n",
       "      <td>...</td>\n",
       "      <td>31.528498</td>\n",
       "      <td>33.711967</td>\n",
       "      <td>29.996479</td>\n",
       "      <td>23.188408</td>\n",
       "      <td>-44.869629</td>\n",
       "      <td>-38.005630</td>\n",
       "      <td>-32.812405</td>\n",
       "      <td>-39.487026</td>\n",
       "      <td>-37.800091</td>\n",
       "      <td>-36.686817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>-0.002671</td>\n",
       "      <td>0.004307</td>\n",
       "      <td>0.128504</td>\n",
       "      <td>0.174134</td>\n",
       "      <td>0.232075</td>\n",
       "      <td>0.250948</td>\n",
       "      <td>0.041101</td>\n",
       "      <td>0.046259</td>\n",
       "      <td>0.281126</td>\n",
       "      <td>0.418759</td>\n",
       "      <td>...</td>\n",
       "      <td>1.095721</td>\n",
       "      <td>1.719861</td>\n",
       "      <td>2.127217</td>\n",
       "      <td>2.192224</td>\n",
       "      <td>-0.095862</td>\n",
       "      <td>-0.094754</td>\n",
       "      <td>-0.123092</td>\n",
       "      <td>-0.256831</td>\n",
       "      <td>-0.274332</td>\n",
       "      <td>-0.558706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>745</td>\n",
       "      <td>0.157937</td>\n",
       "      <td>0.527264</td>\n",
       "      <td>0.895451</td>\n",
       "      <td>1.329056</td>\n",
       "      <td>1.227214</td>\n",
       "      <td>0.964163</td>\n",
       "      <td>0.320467</td>\n",
       "      <td>2.387648</td>\n",
       "      <td>2.941722</td>\n",
       "      <td>3.217043</td>\n",
       "      <td>...</td>\n",
       "      <td>20.322405</td>\n",
       "      <td>18.697315</td>\n",
       "      <td>16.823721</td>\n",
       "      <td>11.039402</td>\n",
       "      <td>-0.287152</td>\n",
       "      <td>-0.329730</td>\n",
       "      <td>-0.198360</td>\n",
       "      <td>-0.451884</td>\n",
       "      <td>-0.480905</td>\n",
       "      <td>-0.826227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1124</td>\n",
       "      <td>0.026324</td>\n",
       "      <td>0.171124</td>\n",
       "      <td>0.382707</td>\n",
       "      <td>0.414283</td>\n",
       "      <td>0.371966</td>\n",
       "      <td>0.255909</td>\n",
       "      <td>0.041623</td>\n",
       "      <td>0.285635</td>\n",
       "      <td>0.792699</td>\n",
       "      <td>0.976086</td>\n",
       "      <td>...</td>\n",
       "      <td>3.968275</td>\n",
       "      <td>5.194155</td>\n",
       "      <td>5.305183</td>\n",
       "      <td>3.692601</td>\n",
       "      <td>-0.080758</td>\n",
       "      <td>-0.074009</td>\n",
       "      <td>-0.076513</td>\n",
       "      <td>-0.101970</td>\n",
       "      <td>-0.489360</td>\n",
       "      <td>-0.368371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130739978</td>\n",
       "      <td>1.422760</td>\n",
       "      <td>11.592505</td>\n",
       "      <td>1.599211</td>\n",
       "      <td>4.687986</td>\n",
       "      <td>-1.693461</td>\n",
       "      <td>19.014822</td>\n",
       "      <td>13.282038</td>\n",
       "      <td>41.883793</td>\n",
       "      <td>8.692912</td>\n",
       "      <td>4.975391</td>\n",
       "      <td>...</td>\n",
       "      <td>35.503822</td>\n",
       "      <td>18.029779</td>\n",
       "      <td>14.617792</td>\n",
       "      <td>430.005585</td>\n",
       "      <td>-19.813738</td>\n",
       "      <td>-3.701869</td>\n",
       "      <td>-5.716228</td>\n",
       "      <td>-3.713967</td>\n",
       "      <td>-21.628431</td>\n",
       "      <td>-82.479317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130755807</td>\n",
       "      <td>0.725015</td>\n",
       "      <td>0.205469</td>\n",
       "      <td>-0.021201</td>\n",
       "      <td>0.805642</td>\n",
       "      <td>1.222313</td>\n",
       "      <td>0.091906</td>\n",
       "      <td>2.244568</td>\n",
       "      <td>0.455759</td>\n",
       "      <td>0.052020</td>\n",
       "      <td>2.578640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050795</td>\n",
       "      <td>9.654325</td>\n",
       "      <td>10.642774</td>\n",
       "      <td>2.014629</td>\n",
       "      <td>-0.543207</td>\n",
       "      <td>-0.054628</td>\n",
       "      <td>-0.096152</td>\n",
       "      <td>-0.891813</td>\n",
       "      <td>-1.173656</td>\n",
       "      <td>-0.700877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130762946</td>\n",
       "      <td>0.031967</td>\n",
       "      <td>-19.712677</td>\n",
       "      <td>-28.527233</td>\n",
       "      <td>-14.739201</td>\n",
       "      <td>-15.416134</td>\n",
       "      <td>-10.772908</td>\n",
       "      <td>14.974207</td>\n",
       "      <td>15.471964</td>\n",
       "      <td>25.912512</td>\n",
       "      <td>25.454903</td>\n",
       "      <td>...</td>\n",
       "      <td>21.063087</td>\n",
       "      <td>38.645321</td>\n",
       "      <td>5.648650</td>\n",
       "      <td>49.731503</td>\n",
       "      <td>-36.691898</td>\n",
       "      <td>-61.140427</td>\n",
       "      <td>-72.320488</td>\n",
       "      <td>-60.707165</td>\n",
       "      <td>-31.057060</td>\n",
       "      <td>-57.803970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130772921</td>\n",
       "      <td>3.157643</td>\n",
       "      <td>28.301941</td>\n",
       "      <td>0.727620</td>\n",
       "      <td>-0.588218</td>\n",
       "      <td>-0.782045</td>\n",
       "      <td>8.299319</td>\n",
       "      <td>9.124571</td>\n",
       "      <td>97.320076</td>\n",
       "      <td>5.545393</td>\n",
       "      <td>2.962431</td>\n",
       "      <td>...</td>\n",
       "      <td>23.823160</td>\n",
       "      <td>7.349889</td>\n",
       "      <td>7.779712</td>\n",
       "      <td>153.784729</td>\n",
       "      <td>-7.293675</td>\n",
       "      <td>-5.249303</td>\n",
       "      <td>-5.461375</td>\n",
       "      <td>-5.472766</td>\n",
       "      <td>-8.767235</td>\n",
       "      <td>-32.409897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130779836</td>\n",
       "      <td>809.681702</td>\n",
       "      <td>724.413818</td>\n",
       "      <td>2686.634521</td>\n",
       "      <td>755.593689</td>\n",
       "      <td>3486.201172</td>\n",
       "      <td>4150.092773</td>\n",
       "      <td>2108.869141</td>\n",
       "      <td>1195.495361</td>\n",
       "      <td>6423.444336</td>\n",
       "      <td>1442.236450</td>\n",
       "      <td>...</td>\n",
       "      <td>31346.531250</td>\n",
       "      <td>4990.029785</td>\n",
       "      <td>54906.308594</td>\n",
       "      <td>29043.628906</td>\n",
       "      <td>-40.707783</td>\n",
       "      <td>-34.069359</td>\n",
       "      <td>-14.442954</td>\n",
       "      <td>-41.575626</td>\n",
       "      <td>-72.575218</td>\n",
       "      <td>-86.271164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7848 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean_0      mean_1       mean_2      mean_3       mean_4  \\\n",
       "object_id                                                                 \n",
       "615         -3.280875 -385.686066  -134.144547 -121.101494   -55.947735   \n",
       "713         -9.234099   -3.436403    -2.644122   -3.357972    -3.113960   \n",
       "730         -0.002671    0.004307     0.128504    0.174134     0.232075   \n",
       "745          0.157937    0.527264     0.895451    1.329056     1.227214   \n",
       "1124         0.026324    0.171124     0.382707    0.414283     0.371966   \n",
       "...               ...         ...          ...         ...          ...   \n",
       "130739978    1.422760   11.592505     1.599211    4.687986    -1.693461   \n",
       "130755807    0.725015    0.205469    -0.021201    0.805642     1.222313   \n",
       "130762946    0.031967  -19.712677   -28.527233  -14.739201   -15.416134   \n",
       "130772921    3.157643   28.301941     0.727620   -0.588218    -0.782045   \n",
       "130779836  809.681702  724.413818  2686.634521  755.593689  3486.201172   \n",
       "\n",
       "                mean_5        std_0        std_1        std_2        std_3  \\\n",
       "object_id                                                                    \n",
       "615         -47.465115    83.769569   601.738953   455.090881   335.389160   \n",
       "713          -6.039946    21.060951    17.820436    18.172571    20.005138   \n",
       "730           0.250948     0.041101     0.046259     0.281126     0.418759   \n",
       "745           0.964163     0.320467     2.387648     2.941722     3.217043   \n",
       "1124          0.255909     0.041623     0.285635     0.792699     0.976086   \n",
       "...                ...          ...          ...          ...          ...   \n",
       "130739978    19.014822    13.282038    41.883793     8.692912     4.975391   \n",
       "130755807     0.091906     2.244568     0.455759     0.052020     2.578640   \n",
       "130762946   -10.772908    14.974207    15.471964    25.912512    25.454903   \n",
       "130772921     8.299319     9.124571    97.320076     5.545393     2.962431   \n",
       "130779836  4150.092773  2108.869141  1195.495361  6423.444336  1442.236450   \n",
       "\n",
       "           ...         max_2        max_3         max_4         max_5  \\\n",
       "object_id  ...                                                          \n",
       "615        ...    611.929565   445.658356    381.876129    377.994080   \n",
       "713        ...     31.528498    33.711967     29.996479     23.188408   \n",
       "730        ...      1.095721     1.719861      2.127217      2.192224   \n",
       "745        ...     20.322405    18.697315     16.823721     11.039402   \n",
       "1124       ...      3.968275     5.194155      5.305183      3.692601   \n",
       "...        ...           ...          ...           ...           ...   \n",
       "130739978  ...     35.503822    18.029779     14.617792    430.005585   \n",
       "130755807  ...      0.050795     9.654325     10.642774      2.014629   \n",
       "130762946  ...     21.063087    38.645321      5.648650     49.731503   \n",
       "130772921  ...     23.823160     7.349889      7.779712    153.784729   \n",
       "130779836  ...  31346.531250  4990.029785  54906.308594  29043.628906   \n",
       "\n",
       "                min_0        min_1       min_2       min_3       min_4  \\\n",
       "object_id                                                                \n",
       "615       -116.758644 -1100.351196 -681.815735 -530.595459 -422.112610   \n",
       "713        -44.869629   -38.005630  -32.812405  -39.487026  -37.800091   \n",
       "730         -0.095862    -0.094754   -0.123092   -0.256831   -0.274332   \n",
       "745         -0.287152    -0.329730   -0.198360   -0.451884   -0.480905   \n",
       "1124        -0.080758    -0.074009   -0.076513   -0.101970   -0.489360   \n",
       "...               ...          ...         ...         ...         ...   \n",
       "130739978  -19.813738    -3.701869   -5.716228   -3.713967  -21.628431   \n",
       "130755807   -0.543207    -0.054628   -0.096152   -0.891813   -1.173656   \n",
       "130762946  -36.691898   -61.140427  -72.320488  -60.707165  -31.057060   \n",
       "130772921   -7.293675    -5.249303   -5.461375   -5.472766   -8.767235   \n",
       "130779836  -40.707783   -34.069359  -14.442954  -41.575626  -72.575218   \n",
       "\n",
       "                min_5  \n",
       "object_id              \n",
       "615       -422.530182  \n",
       "713        -36.686817  \n",
       "730         -0.558706  \n",
       "745         -0.826227  \n",
       "1124        -0.368371  \n",
       "...               ...  \n",
       "130739978  -82.479317  \n",
       "130755807   -0.700877  \n",
       "130762946  -57.803970  \n",
       "130772921  -32.409897  \n",
       "130779836  -86.271164  \n",
       "\n",
       "[7848 rows x 24 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "band_aggs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # this way of calculating quantiles is faster than using the pandas quantile builtin on the groupby object\n",
    "    all_data['group_count'] = all_data.groupby(['object_id', 'passband']).cumcount()\n",
    "    all_data['group_size'] = all_data.groupby(['object_id', 'passband'])['flux'].transform('size')\n",
    "    q_list = [0.25, 0.75]\n",
    "    for q in q_list:\n",
    "        all_data['q_' + str(q)] = all_data.loc[\n",
    "            (all_data['group_size'] * q).astype(int) == all_data['group_count'], 'flux']\n",
    "    quantiles = all_data.groupby(['object_id', 'passband'])[['q_' + str(q) for q in q_list]].max().unstack(-1)\n",
    "    quantiles.columns = [str(x) + '_' + str(y) + '_quantile' for x in quantiles.columns.levels[0]\n",
    "                         for y in quantiles.columns.levels[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # max detected flux\n",
    "    max_detected = all_data.loc[all_data['detected'] == 1].groupby('object_id')['flux'].max().to_frame('max_detected')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_detected</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>615</td>\n",
       "      <td>660.555237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>713</td>\n",
       "      <td>33.711967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.192224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>745</td>\n",
       "      <td>20.322405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1124</td>\n",
       "      <td>5.305183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130739978</td>\n",
       "      <td>430.005585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130755807</td>\n",
       "      <td>10.642774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130762946</td>\n",
       "      <td>-35.704021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130772921</td>\n",
       "      <td>321.631409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130779836</td>\n",
       "      <td>54906.308594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7848 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           max_detected\n",
       "object_id              \n",
       "615          660.555237\n",
       "713           33.711967\n",
       "730            2.192224\n",
       "745           20.322405\n",
       "1124           5.305183\n",
       "...                 ...\n",
       "130739978    430.005585\n",
       "130755807     10.642774\n",
       "130762946    -35.704021\n",
       "130772921    321.631409\n",
       "130779836  54906.308594\n",
       "\n",
       "[7848 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def most_extreme(df_in, k, positive=True, suffix='', include_max=True, include_dur=True, include_interval=False):\n",
    "        # find the \"most extreme\" time for each object, and for each band, retrieve the k data points on either side\n",
    "        # k points before\n",
    "        df = df_in.copy()\n",
    "        df['object_passband_mean'] = df.groupby(['object_id', 'passband'])['flux'].transform('median')\n",
    "        if positive:\n",
    "            df['dist_from_mean'] = (df['flux'] - df['object_passband_mean'])\n",
    "        else:\n",
    "            df['dist_from_mean'] = -(df['flux'] - df['object_passband_mean'])\n",
    "\n",
    "        max_time = df.loc[df['detected'] == 1].groupby('object_id')['dist_from_mean'].idxmax().to_frame(\n",
    "            'max_ind')\n",
    "        max_time['mjd_max' + suffix] = df.loc[max_time['max_ind'].values, 'mjd'].values\n",
    "        df = pd.merge(df, max_time[['mjd_max' + suffix]], 'left', left_on=['object_id'], right_index=True)\n",
    "        df['time_after_mjd_max'] = df['mjd'] - df['mjd_max' + suffix]\n",
    "        df['time_before_mjd_max'] = -df['time_after_mjd_max']\n",
    "\n",
    "        # first k after event\n",
    "        df.sort_values(['object_id', 'passband', 'time_after_mjd_max'], inplace=True)\n",
    "        df['row_num_after'] = df.loc[df['time_after_mjd_max'] >= 0].groupby(\n",
    "            ['object_id', 'passband']).cumcount()\n",
    "        first_k_after = df.loc[(df['row_num_after'] < k) & (df['time_after_mjd_max'] <= 50),\n",
    "                              ['object_id', 'passband', 'flux', 'row_num_after']]\n",
    "        first_k_after.set_index(['object_id', 'passband', 'row_num_after'], inplace=True)\n",
    "        first_k_after = first_k_after.unstack(level=-1).unstack(level=-1)\n",
    "        first_k_after.columns = [str(x) + '_' + str(y) + '_after' for x in first_k_after.columns.levels[1]\n",
    "                                 for y in first_k_after.columns.levels[2]]\n",
    "        extreme_data = first_k_after\n",
    "        time_bands = [[-50, -20], [-20, -10], [-10, 0], [0, 10], [10, 20], [20, 50], [50, 100], [100, 200], [200, 500]]\n",
    "        if include_interval:\n",
    "            interval_arr = []\n",
    "            for start, end in time_bands:\n",
    "                band_data = df.loc[(start <= df['time_after_mjd_max']) & (df['time_after_mjd_max'] <= end)]\n",
    "                interval_agg = band_data.groupby(['object_id', 'passband'])['flux'].mean().unstack(-1)\n",
    "                interval_agg.columns = ['{}_start_{}_end_{}'.format(c, start, end) for c in interval_agg.columns]\n",
    "                interval_arr.append(interval_agg)\n",
    "            interval_data = pd.concat(interval_arr, axis=1)\n",
    "            extreme_data = pd.concat([extreme_data, interval_data], axis=1)\n",
    "        if include_dur:\n",
    "            # detection duration in each passband after event\n",
    "            duration_after = df.loc[(df['time_after_mjd_max'] >= 0) & (df['detected'] == 0)] \\\n",
    "                .groupby(['object_id', 'passband'])['time_after_mjd_max'].first().unstack(-1)\n",
    "            duration_after.columns = ['dur_after_' + str(c) for c in range(6)]\n",
    "            extreme_data = pd.concat([extreme_data, duration_after], axis=1)\n",
    "\n",
    "        # last k before event\n",
    "        df.sort_values(['object_id', 'passband', 'time_before_mjd_max'], inplace=True)\n",
    "        df['row_num_before'] = df.loc[df['time_before_mjd_max'] >= 0].groupby(\n",
    "            ['object_id', 'passband']).cumcount()\n",
    "        first_k_before = df.loc[(df['row_num_before'] < k) & (df['time_after_mjd_max'] <= 50),\n",
    "                                ['object_id', 'passband', 'flux', 'row_num_before']]\n",
    "        first_k_before.set_index(['object_id', 'passband', 'row_num_before'], inplace=True)\n",
    "        first_k_before = first_k_before.unstack(level=-1).unstack(level=-1)\n",
    "        first_k_before.columns = [str(x) + '_' + str(y) + '_before' for x in first_k_before.columns.levels[1]\n",
    "                                  for y in first_k_before.columns.levels[2]]\n",
    "        extreme_data = pd.concat([extreme_data, first_k_before], axis=1)\n",
    "        if include_dur:\n",
    "            # detection duration in each passband before event\n",
    "            duration_before = df.loc[(df['time_before_mjd_max'] >= 0) & (df['detected'] == 0)] \\\n",
    "                .groupby(['object_id', 'passband'])['time_before_mjd_max'].first().unstack(-1)\n",
    "            duration_before.columns = ['dur_before_' + str(c) for c in range(6)]\n",
    "            extreme_data = pd.concat([extreme_data, duration_before], axis=1)\n",
    "\n",
    "        if include_max:\n",
    "            # passband with maximum detected flux for each object\n",
    "            max_pb = df.loc[max_time['max_ind'].values].groupby('object_id')['passband'].max().to_frame(\n",
    "                'max_passband')\n",
    "            # time of max in each passband, relative to extreme max\n",
    "            band_max_ind = df.groupby(['object_id', 'passband'])['flux'].idxmax()\n",
    "            band_mjd_max = df.loc[band_max_ind.values].groupby(['object_id', 'passband'])['mjd'].max().unstack(-1)\n",
    "            cols = ['max_time_' + str(i) for i in range(6)]\n",
    "            band_mjd_max.columns = cols\n",
    "            band_mjd_max = pd.merge(band_mjd_max, max_time, 'left', 'object_id')\n",
    "            for c in cols:\n",
    "                band_mjd_max[c] -= band_mjd_max['mjd_max' + suffix]\n",
    "            band_mjd_max.drop(['mjd_max' + suffix, 'max_ind'], axis=1, inplace=True)\n",
    "            extreme_data = pd.concat([extreme_data, max_pb, band_mjd_max], axis=1)\n",
    "\n",
    "        extreme_data.columns = [c + suffix for c in extreme_data.columns]\n",
    "        return extreme_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "    extreme_max = most_extreme(all_data, 1, positive=True, suffix='', include_max=True, include_dur=True,\n",
    "                               include_interval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "    extreme_min = most_extreme(all_data, 1, positive=False, suffix='_min', include_max=False, include_dur=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0.0_0_after', '0.0_1_after', '0.0_2_after', '0.0_3_after',\n",
       "       '0.0_4_after', '0.0_5_after', '0_start_-50_end_-20',\n",
       "       '1_start_-50_end_-20', '2_start_-50_end_-20', '3_start_-50_end_-20',\n",
       "       '4_start_-50_end_-20', '5_start_-50_end_-20', '0_start_-20_end_-10',\n",
       "       '1_start_-20_end_-10', '2_start_-20_end_-10', '3_start_-20_end_-10',\n",
       "       '4_start_-20_end_-10', '5_start_-20_end_-10', '0_start_-10_end_0',\n",
       "       '1_start_-10_end_0', '2_start_-10_end_0', '3_start_-10_end_0',\n",
       "       '4_start_-10_end_0', '5_start_-10_end_0', '0_start_0_end_10',\n",
       "       '1_start_0_end_10', '2_start_0_end_10', '3_start_0_end_10',\n",
       "       '4_start_0_end_10', '5_start_0_end_10', '0_start_10_end_20',\n",
       "       '1_start_10_end_20', '2_start_10_end_20', '3_start_10_end_20',\n",
       "       '4_start_10_end_20', '5_start_10_end_20', '0_start_20_end_50',\n",
       "       '1_start_20_end_50', '2_start_20_end_50', '3_start_20_end_50',\n",
       "       '4_start_20_end_50', '5_start_20_end_50', '0_start_50_end_100',\n",
       "       '1_start_50_end_100', '2_start_50_end_100', '3_start_50_end_100',\n",
       "       '4_start_50_end_100', '5_start_50_end_100', '0_start_100_end_200',\n",
       "       '1_start_100_end_200', '2_start_100_end_200', '3_start_100_end_200',\n",
       "       '4_start_100_end_200', '5_start_100_end_200', '0_start_200_end_500',\n",
       "       '1_start_200_end_500', '2_start_200_end_500', '3_start_200_end_500',\n",
       "       '4_start_200_end_500', '5_start_200_end_500', 'dur_after_0',\n",
       "       'dur_after_1', 'dur_after_2', 'dur_after_3', 'dur_after_4',\n",
       "       'dur_after_5', '0.0_0_before', '0.0_1_before', '0.0_2_before',\n",
       "       '0.0_3_before', '0.0_4_before', '0.0_5_before', 'dur_before_0',\n",
       "       'dur_before_1', 'dur_before_2', 'dur_before_3', 'dur_before_4',\n",
       "       'dur_before_5', 'max_passband', 'max_time_0', 'max_time_1',\n",
       "       'max_time_2', 'max_time_3', 'max_time_4', 'max_time_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extreme_max.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # add the feature mentioned here, attempts to identify periodicity:\n",
    "    # https://www.kaggle.com/c/PLAsTiCC-2018/discussion/69696#410538\n",
    "    time_between_detections = all_data.loc[all_data['detected'] == 1].groupby('object_id')['mjd'].agg(['max', 'min'])\n",
    "    time_between_detections['det_period'] = time_between_detections['max'] - time_between_detections['min']\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # same feature but grouped by passband\n",
    "    time_between_detections_pb \\\n",
    "        = all_data.loc[all_data['detected'] == 1].groupby(['object_id', 'passband'])['mjd'].agg(['max', 'min'])\n",
    "    time_between_detections_pb['det_period'] = time_between_detections_pb['max'] - time_between_detections_pb['min']\n",
    "    time_between_detections_pb = time_between_detections_pb['det_period'].unstack(-1)\n",
    "    time_between_detections_pb.columns = ['det_period_pb_' + str(i) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # similar feature based on high values\n",
    "    all_data['threshold'] = all_data.groupby(['object_id'])['flux'].transform('max') * 0.75\n",
    "    all_data['high'] = ((all_data['flux'] >= all_data['threshold']) & (all_data['detected'] == 1)).astype(int)\n",
    "    time_between_highs = all_data.loc[all_data['high'] == 1].groupby('object_id')['mjd'].agg(['max', 'min'])\n",
    "    time_between_highs['det_period_high'] = time_between_highs['max'] - time_between_highs['min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # aggregate values of the features during the detection period\n",
    "    all_data = pd.merge(all_data, time_between_detections, 'left', 'object_id')\n",
    "    det_data = all_data.loc[(all_data['mjd'] >= all_data['min']) & (all_data['mjd'] <= all_data['max'])]\n",
    "    det_aggs = det_data.groupby(['object_id', 'passband'])['flux'].agg(['min', 'max', 'std', 'median'])\n",
    "    det_aggs['prop_detected'] = det_data.groupby(['object_id', 'passband'])['detected'].mean()\n",
    "    det_aggs = det_aggs.unstack(-1)\n",
    "    det_aggs.columns = [x + '_' + str(y) + '_det_period' for x in det_aggs.columns.levels[0]\n",
    "                          for y in det_aggs.columns.levels[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # time distribution of detections in each band\n",
    "    detection_time_dist \\\n",
    "        = all_data.loc[all_data['detected'] == 1].groupby(['object_id', 'passband'])['mjd'].std().unstack(-1)\n",
    "    detection_time_dist.columns = ['time_dist_' + str(i) for i in range(6)]\n",
    "    detection_time_dist_all \\\n",
    "        = all_data.loc[all_data['detected'] == 1].groupby(['object_id'])['mjd'].std().to_frame('time_dist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # scale data and recalculate band aggs\n",
    "    all_data['abs_flux'] = all_data['flux'].abs()\n",
    "    all_data['flux'] = (all_data['flux']) / all_data.groupby('object_id')['abs_flux'].transform('max')\n",
    "    band_aggs_s = all_data.groupby(['object_id', 'passband'])['flux'].agg(['mean', 'std', 'max', 'min']).unstack(-1)\n",
    "    band_aggs_s.columns = [x + '_' + str(y) + '_scaled' for x in band_aggs_s.columns.levels[0]\n",
    "                          for y in band_aggs_s.columns.levels[1]]\n",
    "    all_data.sort_values(['object_id', 'passband', 'flux'], inplace=True)\n",
    "    for q in q_list:\n",
    "        all_data['q_' + str(q)] = all_data.loc[\n",
    "            (all_data['group_size'] * q).astype(int) == all_data['group_count'], 'flux']\n",
    "    quantiles_s = all_data.groupby(['object_id', 'passband'])[['q_' + str(q) for q in q_list]].max().unstack(-1)\n",
    "    quantiles_s.columns = [str(x) + '_' + str(y) + '_quantile_s' for x in quantiles_s.columns.levels[0]\n",
    "                          for y in quantiles_s.columns.levels[1]]\n",
    "\n",
    "    extreme_max_s = most_extreme(all_data, 1, positive=True, suffix='_s', include_max=False, include_dur=False,\n",
    "                                 include_interval=True)\n",
    "    extreme_min_s = most_extreme(all_data, 1, positive=False, suffix='_min_s', include_max=False, include_dur=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    new_data = pd.concat([band_aggs, quantiles, band_aggs_s, max_detected, time_between_detections[['det_period']],\n",
    "                          time_between_detections_pb, extreme_max, extreme_min, extreme_max_s, extreme_min_s,\n",
    "                          time_between_highs[['det_period_high']], quantiles_s, detection_time_dist,\n",
    "                          detection_time_dist_all, det_aggs], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7848, 305)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# thus there are 305 features\n",
    "* in summary -\n",
    "* start with \"metadata\" and \"timeseries\" data\n",
    "* the \"metadata\" is based on object_id, and is the destination for all generated features\n",
    "* we generate features, mostly using the timeseries data\n",
    "  * (coalesce the timeseries data into features, to add to the metadata)\n",
    "* in the end we go from (7848,12) to (7848, 305)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_0', 'mean_1', 'mean_2', 'mean_3', 'mean_4', 'mean_5', 'std_0',\n",
       "       'std_1', 'std_2', 'std_3',\n",
       "       ...\n",
       "       'median_2_det_period', 'median_3_det_period', 'median_4_det_period',\n",
       "       'median_5_det_period', 'prop_detected_0_det_period',\n",
       "       'prop_detected_1_det_period', 'prop_detected_2_det_period',\n",
       "       'prop_detected_3_det_period', 'prop_detected_4_det_period',\n",
       "       'prop_detected_5_det_period'],\n",
       "      dtype='object', length=305)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# she then repeats this using \"approx\" data (spez vs photoz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process training set (not actually used, just to get right shape of dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process test set (done in \"chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (Section 2 in the .pdf)\n",
    "* this is implemented in the code as \"predict.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Gradient Boosted Classification Tree**\n",
    "* **Separate model for each class:**\n",
    "  * (each class in the Training data is either only galactic or only extra-galactic)\n",
    "  * (hostgal_photoz = 1)\n",
    "  * Thus -> she trains model for galactic classes on galactic data, and extra-galactic classes using extra-galactic data)\n",
    "* **Train separate models for \"exact\" and \"approximate\" redshift**\n",
    "* **Test data is quite different than training ...**\n",
    "  * To prevent overfitting used early stopping in LightGBM\n",
    "  * validation set sampled from training data - resampled w/ distribution to reflect test data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... having trouble importing lightgbm.  see:\n",
    "https://github.com/Microsoft/LightGBM/issues/566\n",
    "\n",
    "```\n",
    "need to run python **64bit** not **32bit**\n",
    "https://www.python.org/downloads/windows/\n",
    "\n",
    "python 3.7.5 **64-bit**\n",
    "+=================================\n",
    "when running python 64bit ...\n",
    "\n",
    "need to install scipy and scikit_learn using \"wheel\" file\n",
    "\n",
    "  26 pip install C:\\Users\\Chris\\Downloads\\scipy-1.3.1-cp38-cp38-win_amd64.whl\n",
    "  28 pip install C:\\Users\\Chris\\Downloads\\scikit_learn-0.21.3-cp38-cp38-win_amd64.whl\n",
    "\n",
    "References:\n",
    "    https://stackoverflow.com/questions/26657334/installing-numpy-and-scipy-on-64-bit-windows-with-pip\n",
    "    https://www.lfd.uci.edu/~gohlke/pythonlibs/#scipy\n",
    "    https://pip.pypa.io/en/latest/user_guide/#installing-from-wheels\n",
    "\n",
    "+============\n",
    "to script this... (to be done)\n",
    "Invoke-WebRequest cmdlet\n",
    "https://4sysops.com/archives/use-powershell-to-download-a-file-with-http-https-and-ftp/\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics, model_selection\n",
    "import lightgbm as lgb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if test_mode is True, just run training and cross-validation on training data;\n",
    "# if False, also make predictions on test set\n",
    "test_mode = False\n",
    "\n",
    "# read data\n",
    "all_meta = pd.read_hdf(os.path.join('data', 'features', 'all_data.hdf5'), key='file0')\n",
    "train_meta_approx = pd.read_hdf(os.path.join('data', 'features', 'train_meta_approx.hdf5'), key='file0')\n",
    "train_meta_exact = pd.read_hdf(os.path.join('data', 'features', 'train_meta_exact.hdf5'), key='file0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
