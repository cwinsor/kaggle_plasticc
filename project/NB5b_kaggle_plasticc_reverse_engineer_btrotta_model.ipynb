{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook we continue with \"btrotta\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (Section 2 in the .pdf)\n",
    "* this is implemented in the code as \"predict.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Gradient Boosted Classification Tree**\n",
    "* **Separate model for each class:**\n",
    "  * (each class in the Training data is either only galactic or only extra-galactic)\n",
    "  * (hostgal_photoz = 1)\n",
    "  * Thus -> she trains model for galactic classes on galactic data, and extra-galactic classes using extra-galactic data)\n",
    "* **Train separate models for \"exact\" and \"approximate\" redshift**\n",
    "* **Test data is quite different than training ...**\n",
    "  * To prevent overfitting used early stopping in LightGBM\n",
    "  * validation set sampled from training data - resampled w/ distribution to reflect test data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... having trouble importing lightgbm.  see:\n",
    "https://github.com/Microsoft/LightGBM/issues/566\n",
    "\n",
    "```\n",
    "need to run python **64bit** not **32bit**\n",
    "https://www.python.org/downloads/windows/\n",
    "\n",
    "python 3.7.5 **64-bit**\n",
    "+=================================\n",
    "when running python 64bit ...\n",
    "\n",
    "need to install scipy and scikit_learn using \"wheel\" file\n",
    "\n",
    "  26 pip install C:\\Users\\Chris\\Downloads\\scipy-1.3.1-cp38-cp38-win_amd64.whl\n",
    "  28 pip install C:\\Users\\Chris\\Downloads\\scikit_learn-0.21.3-cp38-cp38-win_amd64.whl\n",
    "\n",
    "References:\n",
    "    https://stackoverflow.com/questions/26657334/installing-numpy-and-scipy-on-64-bit-windows-with-pip\n",
    "    https://www.lfd.uci.edu/~gohlke/pythonlibs/#scipy\n",
    "    https://pip.pypa.io/en/latest/user_guide/#installing-from-wheels\n",
    "\n",
    "+============\n",
    "to script this... (to be done)\n",
    "Invoke-WebRequest cmdlet\n",
    "https://4sysops.com/archives/use-powershell-to-download-a-file-with-http-https-and-ftp/\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics, model_selection\n",
    "import lightgbm as lgb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File data\\features\\all_data.hdf5 does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c90b203b2ef3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# read data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mall_meta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'features'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'all_data.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'file0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtrain_meta_approx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'features'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train_meta_approx.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'file0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtrain_meta_exact\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'features'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train_meta_exact.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'file0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\documents\\code_kaggle_plasticc\\kaggle_plasticc\\project\\pymote_env\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mread_hdf\u001b[1;34m(path_or_buf, key, mode, **kwargs)\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mexists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m             raise FileNotFoundError(\n\u001b[1;32m--> 381\u001b[1;33m                 \u001b[1;34m\"File {path} does not exist\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m             )\n\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File data\\features\\all_data.hdf5 does not exist"
     ]
    }
   ],
   "source": [
    "# if test_mode is True, just run training and cross-validation on training data;\n",
    "# if False, also make predictions on test set\n",
    "test_mode = False\n",
    "\n",
    "# read data\n",
    "all_meta = pd.read_hdf(os.path.join('data', 'features', 'all_data.hdf5'), key='file0')\n",
    "train_meta_approx = pd.read_hdf(os.path.join('data', 'features', 'train_meta_approx.hdf5'), key='file0')\n",
    "train_meta_exact = pd.read_hdf(os.path.join('data', 'features', 'train_meta_exact.hdf5'), key='file0')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# But first a review on LightGBM...\n",
    "* https://mlexplained.com/2018/01/05/lightgbm-and-xgboost-explained/  ***<--a \"must-read\"***\n",
    "* https://lightgbm.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Decision Trees (GBDT)\n",
    "* **Common implementations:**\n",
    "  * xboost (came into favor ~2015)\n",
    "  * LightGBM (Microsoft ~2018)\n",
    "  \n",
    "\n",
    "* **Algorithm:**\n",
    "\n",
    "  1. Create a decision tree \"Model 1\"\n",
    "    1. at each node choose attribute (entropy, information gain)\n",
    "    * build sub-nodes, repeating downward to build tree\n",
    "    * stop when some limit is reached:\n",
    "      * no more attributes (exhaustive)\n",
    "      * meet some criterion based on loss function... f(class, regularization)\n",
    "      * meet some criterion based on early-stopping\n",
    "    * post-pruning\n",
    "\n",
    "  * Create a modified version of the dataset\n",
    "    * New Class = original dataset class - prediction from Model 1 \n",
    "    * ***i.e. the \"New Class\" is the \"residual\" (error left behind from Model 1)***\n",
    "    * we are building a model to predict the error...\n",
    "    * `y = m1(x) + e`\n",
    "      * where:\n",
    "        * y is the class\n",
    "        * m1(x) is m1's prediction of y\n",
    "        * \"e\" is the error\n",
    "    * solving for \"e\"\n",
    "      * `e = y - m1(x)`\n",
    "\n",
    "  * Create a NEW decision tree (\"Model 2\")\n",
    "    * <same steps as above, but predicting the New Class variable\n",
    "\n",
    "  * **We now have 2 models**\n",
    "    * The prediction of the first is good\n",
    "    * The prediction of the second, **when added to the first,** ***is better***\n",
    "\n",
    "  * Repeat (building more models, each predicting the residual...)\n",
    "    * until ...\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters...\n",
    "* subject to overfitting.\n",
    "* done using validation data\n",
    "* \"out of the bag sample\" or \"cross-validation\"\n",
    "* best time to stop when validation error has decreased and starts to stabilize, before starts to increase due to overfitting\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***LightGBM is a gradient boosting framework that uses tree based learning algorithms.***\n",
    "\n",
    "(https://lightgbm.readthedocs.io/en/latest/Experiments.html)\n",
    "\n",
    "***out-performs peers***\n",
    "\n",
    "| | xgboost | xgboost_hist | LightGBM |\n",
    "| --- | --- | --- | --- |\n",
    "| Speed | 3x to 10x | 1.5x to 4x | 1x |\n",
    "| Accuracy | | | 0 to 3% better |\n",
    "| Memory (GB) | 1.5 to 6.2 | 1.4 to 5.0 | 0.8 to 1.0 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'lightgbm.basic.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "train_data = lgb.Dataset('train.svm.bin')\n",
    "print(type(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a numpy array into Dataset:\n",
    "data = np.random.rand(500, 10)  # 500 entities, each contains 10 features\n",
    "label = np.random.randint(2, size=500)  # binary target\n",
    "train_data = lgb.Dataset(data, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.55379504 0.38774458 0.52724296 ... 0.84889923 0.1218365  0.88601886]\n",
      " [0.61361511 0.85954033 0.06751338 ... 0.45436543 0.63363454 0.0256262 ]\n",
      " [0.66805052 0.15698581 0.65909552 ... 0.9920577  0.59019986 0.92296939]\n",
      " ...\n",
      " [0.03583564 0.25896966 0.08475954 ... 0.34839232 0.42582798 0.10397257]\n",
      " [0.68507483 0.56182096 0.18288224 ... 0.29088559 0.0247573  0.70658587]\n",
      " [0.3269044  0.14248502 0.18087515 ... 0.94742193 0.14309186 0.6066268 ]]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import scipy\n",
    "#csr = scipy.sparse.csr_matrix((dat, (row, col)))\n",
    "#train_data = lgb.Dataset(csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Dataset at 0x240d96404c8>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.save_binary('train.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'lightgbm.basic.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "validation_data = train_data.create_valid('validation.svm')\n",
    "print(type(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(data, label=label, feature_name=['c1', 'c2', 'c3'], categorical_feature=['c3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.rand(500, )\n",
    "train_data = lgb.Dataset(data, label=label, weight=w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 31, 'objective': 'binary'}\n",
    "param['metric'] = 'auc'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "param['metric'] = ['auc', 'binary_logloss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "LightGBMError",
     "evalue": "Cannot open data file validation.svm",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-64142b89afed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum_round\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_round\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\chris\\documents\\code_kaggle_plasticc\\kaggle_plasticc\\project\\pymote_env\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname_valid_set\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduced_valid_sets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname_valid_sets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname_valid_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reverse_update_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\documents\\code_kaggle_plasticc\\kaggle_plasticc\\project\\pymote_env\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36madd_valid\u001b[1;34m(self, data, name)\u001b[0m\n\u001b[0;32m   1843\u001b[0m         _safe_call(_LIB.LGBM_BoosterAddValidData(\n\u001b[0;32m   1844\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1845\u001b[1;33m             data.construct().handle))\n\u001b[0m\u001b[0;32m   1846\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_valid_sets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\documents\\code_kaggle_plasticc\\kaggle_plasticc\\project\\pymote_env\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1003\u001b[0m                                     \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m                                     \u001b[0minit_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1005\u001b[1;33m                                     silent=self.silent, feature_name=self.feature_name, params=self.params)\n\u001b[0m\u001b[0;32m   1006\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m                     \u001b[1;31m# construct subset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\documents\\code_kaggle_plasticc\\kaggle_plasticc\\project\\pymote_env\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m    831\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[0mref_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                 ctypes.byref(self.handle)))\n\u001b[0m\u001b[0;32m    834\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init_from_csr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\documents\\code_kaggle_plasticc\\kaggle_plasticc\\project\\pymote_env\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \"\"\"\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecode_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLightGBMError\u001b[0m: Cannot open data file validation.svm"
     ]
    }
   ],
   "source": [
    "num_round = 10\n",
    "bst = lgb.train(param, train_data, num_round, valid_sets=[validation_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
